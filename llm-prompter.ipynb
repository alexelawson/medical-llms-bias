{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for llm from huggingface. \n",
    "Pulls the .csv of the datafile on local computer and outputs and answer. Compares with correct answer. Saves to new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Replace with your deployed API URL\n",
    "API_URL = \"BLANK\"\n",
    "\n",
    "# Replace with your Hugging Face API key\n",
    "HF_TOKEN = \"BLANK\"\n",
    "\n",
    "# API Headers\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/Users/alexlawson/Documents/GitHub/medical-llms-bias/shortened.csv\" # Replace with the path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to format the prompt\n",
    "def format_prompt(question, a, b, c, d):\n",
    "    return (\n",
    "        f\"Answer the following multiple choice question. Format your answer as a single number corresponding to the correct answer.\\n\"\n",
    "        f\"{question}\\n\"\n",
    "        f\"1. {a}\\n\"\n",
    "        f\"2. {b}\\n\"\n",
    "        f\"3. {c}\\n\"\n",
    "        f\"4. {d}\\n\\n\"\n",
    "        f\"Your Answer: \"\n",
    "    )\n",
    "\n",
    "# Function to query the LLM\n",
    "def query_llm(prompt):\n",
    "    data = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 5,  # Forces a short response\n",
    "            \"temperature\": 0.1,  # Ensures deterministic output\n",
    "            \"top_p\": 0.1,  # Reduces variability\n",
    "            \"do_sample\": False,\n",
    "            \"eos_token_id\": 50256\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=HEADERS, json=data)\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Extract the response text\n",
    "        if isinstance(response_json, list) and len(response_json) > 0:\n",
    "            response_text = response_json[0].get(\"generated_text\", \"\").strip()\n",
    "        elif isinstance(response_json, dict) and \"generated_text\" in response_json:\n",
    "            response_text = response_json[\"generated_text\"].strip()\n",
    "        else:\n",
    "            raise KeyError(\"Unexpected response format\")\n",
    "\n",
    "        # Use regex to extract the number following \"Your Answer: \"\n",
    "        match = re.search(r\"Your Answer:\\s*([1-4])\\.\", response_text)\n",
    "        if match:\n",
    "            return match.group(1)  # Extract the number (group 1 from the regex)\n",
    "        else:\n",
    "            return None  # No valid answer found\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process the dataset\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    question = row[\"Augmented_Question\"]\n",
    "    opa = row[\"opa\"]\n",
    "    opb = row[\"opb\"]\n",
    "    opc = row[\"opc\"]\n",
    "    opd = row[\"opd\"]\n",
    "    correct_answer = str(int(row[\"cop\"]) + 1)  # Ensure the correct answer is a string\n",
    "\n",
    "    # Format the prompt\n",
    "    prompt = format_prompt(question, opa, opb, opc, opd)\n",
    "\n",
    "    # Query the LLM\n",
    "    llm_answer = query_llm(prompt)\n",
    "\n",
    "    # Check if the LLM's answer is correct\n",
    "    is_correct = llm_answer == correct_answer\n",
    "\n",
    "    # Append the result\n",
    "    results.append({\n",
    "        \"Question\": question,\n",
    "        \"Correct Answer\": correct_answer,\n",
    "        \"LLM Answer\": llm_answer,\n",
    "        \"Is Correct\": is_correct\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "output_file = \"/Users/alexlawson/Documents/GitHub/medical-llms-bias/results.csv\"  # Replace with the desired output path\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
