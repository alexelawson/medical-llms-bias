{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the multiple-choice model and tokenizer\n",
    "MODEL_NAME = \"model of choice\"  # Replace with actual model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset.csv\")  # Replace with actual dataset path\n",
    "# Filter dataset to only include single-choice questions\n",
    "df = df[df[\"choice_type\"] == \"Single\"]\n",
    "\n",
    "# Extract relevant columns\n",
    "question_col = \"Augmented_Question\"\n",
    "choices_cols = [\"opa\", \"opb\", \"opc\", \"opd\"]\n",
    "correct_col = \"cop\"\n",
    "demographic_cols = [\"Male\", \"Female\", \"White\", \"Black\", \"Arab\", \"Asian\", \"Other\", \"Low\", \"Middle\", \"High\"]\n",
    "\n",
    "# Define prediction function for SHAP\n",
    "def f_mcq(x):\n",
    "    \"\"\"SHAP function to get logits for multiple-choice questions.\"\"\"\n",
    "    # Extract question and choices from SHAP input format\n",
    "    question = x[\"question\"]\n",
    "    choices = x[\"choices\"]\n",
    "    \n",
    "    # Tokenize inputs\n",
    "    inputs = tokenizer(\n",
    "        [question] * len(choices),\n",
    "        choices,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Return logits as numpy array\n",
    "    return outputs.logits.cpu().numpy()\n",
    "\n",
    "# Create a small background dataset for the SHAP explainer\n",
    "background_indices = np.random.choice(len(df), min(10, len(df)), replace=False)\n",
    "background_dataset = []\n",
    "for idx in background_indices:\n",
    "    row = df.iloc[idx]\n",
    "    background_dataset.append({\n",
    "        \"question\": row[question_col],\n",
    "        \"choices\": [row[col] for col in choices_cols if pd.notna(row[col])]\n",
    "    })\n",
    "\n",
    "# Initialize SHAP explainer with proper masker\n",
    "masker = shap.maskers.Text(tokenizer)\n",
    "explainer = shap.Explainer(f_mcq, masker, output_names=[\"opa\", \"opb\", \"opc\", \"opd\"])\n",
    "\n",
    "# Process the dataset\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        # Skip rows with missing data\n",
    "        if any(pd.isna(row[col]) for col in [question_col] + choices_cols):\n",
    "            continue\n",
    "        \n",
    "        # Prepare input for the explainer\n",
    "        sample_input = {\n",
    "            \"question\": row[question_col],\n",
    "            \"choices\": [row[col] for col in choices_cols if pd.notna(row[col])]\n",
    "        }\n",
    "        \n",
    "        # Get SHAP values\n",
    "        shap_values = explainer([sample_input])\n",
    "        \n",
    "        # Get raw model predictions for confidence metrics\n",
    "        logits = f_mcq(sample_input)\n",
    "        probabilities = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "        \n",
    "        # Get tokens from the tokenizer\n",
    "        tokens = tokenizer.convert_ids_to_tokens(shap_values.data[0])\n",
    "        \n",
    "        # Basic data extraction\n",
    "        shap_data = {\n",
    "            \"index\": index,\n",
    "            \"question\": row[question_col],\n",
    "            \"correct_option\": row[correct_col] if correct_col in row else None\n",
    "        }\n",
    "        \n",
    "        # Add demographic information from binary columns\n",
    "        for col in demographic_cols:\n",
    "            if col in row:\n",
    "                shap_data[f\"demographic_{col}\"] = int(row[col])\n",
    "        \n",
    "        # 1. TOKEN-LEVEL IMPORTANCE SCORES\n",
    "        # Sum importance across all choices to get overall token importance\n",
    "        token_importances = np.abs(shap_values.values[0]).sum(axis=0)\n",
    "        \n",
    "        # Find top 10 most important tokens\n",
    "        most_important_indices = np.argsort(token_importances)[-10:][::-1]\n",
    "        \n",
    "        # Store important tokens and their scores\n",
    "        shap_data[\"important_tokens\"] = []\n",
    "        shap_data[\"token_importance_scores\"] = []\n",
    "        \n",
    "        for idx in most_important_indices:\n",
    "            if idx < len(tokens):  # Safety check\n",
    "                token = tokens[idx]\n",
    "                score = float(token_importances[idx])  # Convert to Python float for JSON serialization\n",
    "                shap_data[\"important_tokens\"].append(token)\n",
    "                shap_data[\"token_importance_scores\"].append(score)\n",
    "        \n",
    "        # 2. CONFIDENCE METRICS\n",
    "        # Get overall model confidence\n",
    "        shap_data[\"confidence\"] = float(probabilities.max())\n",
    "        shap_data[\"prediction\"] = int(probabilities.argmax())\n",
    "        \n",
    "        # Calculate entropy (measure of uncertainty)\n",
    "        entropy = -np.sum(probabilities * np.log(probabilities + 1e-10))\n",
    "        shap_data[\"uncertainty_entropy\"] = float(entropy)\n",
    "        \n",
    "        # Calculate how spread out the probabilities are (another uncertainty measure)\n",
    "        spread = np.max(probabilities) - np.min(probabilities)\n",
    "        shap_data[\"confidence_spread\"] = float(spread)\n",
    "        \n",
    "        # 3. BIAS INDICATORS\n",
    "        # Calculate bias indicators based on demographic binary columns\n",
    "        shap_data[\"bias_indicators\"] = {}\n",
    "        \n",
    "        # Store option importance for each choice\n",
    "        option_importances = np.abs(shap_values.values).mean(axis=2)\n",
    "        for i, option in enumerate(choices_cols[:len(sample_input[\"choices\"])]):\n",
    "            if i < option_importances.shape[1]:\n",
    "                shap_data[f\"importance_{option}\"] = float(option_importances[0][i])\n",
    "        \n",
    "        results.append(shap_data)\n",
    "        \n",
    "        # Save visualization for the first few samples\n",
    "        if index < 5:\n",
    "            shap.plots.text(shap_values[0, :, :], save_path=f\"shap_example_{index}.png\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save full results to JSON for better preservation of nested structures\n",
    "import json\n",
    "with open(\"shap_analysis_full_results.json\", \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Create demographic-specific analysis\n",
    "demographic_analysis = {}\n",
    "\n",
    "# Analyze data by demographic groups\n",
    "for demo_col in demographic_cols:\n",
    "    demo_key = f\"demographic_{demo_col}\"\n",
    "    if demo_key in results_df.columns:\n",
    "        # Create a subset of results for this demographic group\n",
    "        demo_results = results_df[results_df[demo_key] == 1]\n",
    "        non_demo_results = results_df[results_df[demo_key] == 0]\n",
    "        \n",
    "        if not demo_results.empty and not non_demo_results.empty:\n",
    "            # Calculate average metrics for demographic comparison\n",
    "            analysis = {\n",
    "                \"total_questions\": len(demo_results),\n",
    "                \"average_confidence\": demo_results[\"confidence\"].mean(),\n",
    "                \"average_uncertainty\": demo_results[\"uncertainty_entropy\"].mean(),\n",
    "                \"option_importance\": {}\n",
    "            }\n",
    "            \n",
    "            # Compare option importance between demographic groups\n",
    "            for option in choices_cols:\n",
    "                option_col = f\"importance_{option}\"\n",
    "                if option_col in demo_results.columns:\n",
    "                    demo_avg = demo_results[option_col].mean()\n",
    "                    non_demo_avg = non_demo_results[option_col].mean()\n",
    "                    \n",
    "                    # Calculate relative importance (how much more/less important for this demographic)\n",
    "                    relative_importance = demo_avg / non_demo_avg if non_demo_avg > 0 else 0\n",
    "                    \n",
    "                    analysis[\"option_importance\"][option] = {\n",
    "                        \"demo_group_avg\": float(demo_avg),\n",
    "                        \"other_group_avg\": float(non_demo_avg),\n",
    "                        \"relative_importance\": float(relative_importance)\n",
    "                    }\n",
    "            \n",
    "            # Compare token importance patterns\n",
    "            # Aggregate token importance across demographic groups\n",
    "            demo_tokens = {}\n",
    "            non_demo_tokens = {}\n",
    "            \n",
    "            for _, row in demo_results.iterrows():\n",
    "                if \"important_tokens\" in row and \"token_importance_scores\" in row:\n",
    "                    for token, score in zip(row[\"important_tokens\"], row[\"token_importance_scores\"]):\n",
    "                        if token not in demo_tokens:\n",
    "                            demo_tokens[token] = []\n",
    "                        demo_tokens[token].append(score)\n",
    "            \n",
    "            for _, row in non_demo_results.iterrows():\n",
    "                if \"important_tokens\" in row and \"token_importance_scores\" in row:\n",
    "                    for token, score in zip(row[\"important_tokens\"], row[\"token_importance_scores\"]):\n",
    "                        if token not in non_demo_tokens:\n",
    "                            non_demo_tokens[token] = []\n",
    "                        non_demo_tokens[token].append(score)\n",
    "            \n",
    "            # Find tokens that are significantly more important for one demographic group\n",
    "            analysis[\"token_bias\"] = {}\n",
    "            for token in set(demo_tokens.keys()) | set(non_demo_tokens.keys()):\n",
    "                demo_avg = np.mean(demo_tokens.get(token, [0]))\n",
    "                non_demo_avg = np.mean(non_demo_tokens.get(token, [0]))\n",
    "                \n",
    "                if demo_avg > 0 and non_demo_avg > 0:\n",
    "                    relative_importance = demo_avg / non_demo_avg\n",
    "                    \n",
    "                    # Flag tokens with significant bias (more than 2x difference)\n",
    "                    if relative_importance > 2 or relative_importance < 0.5:\n",
    "                        analysis[\"token_bias\"][token] = {\n",
    "                            \"demo_importance\": float(demo_avg),\n",
    "                            \"non_demo_importance\": float(non_demo_avg),\n",
    "                            \"relative_importance\": float(relative_importance)\n",
    "                        }\n",
    "            \n",
    "            demographic_analysis[demo_col] = analysis\n",
    "\n",
    "# Save demographic analysis\n",
    "with open(\"demographic_bias_analysis.json\", \"w\") as f:\n",
    "    json.dump(demographic_analysis, f)\n",
    "\n",
    "# Generate summary report\n",
    "summary = {\n",
    "    \"total_questions_analyzed\": len(results),\n",
    "    \"average_confidence\": results_df[\"confidence\"].mean() if \"confidence\" in results_df else None,\n",
    "    \"average_uncertainty\": results_df[\"uncertainty_entropy\"].mean() if \"uncertainty_entropy\" in results_df else None,\n",
    "    \"demographic_summary\": {}\n",
    "}\n",
    "\n",
    "# Summarize key findings for each demographic group\n",
    "for demo_col, analysis in demographic_analysis.items():\n",
    "    summary[\"demographic_summary\"][demo_col] = {\n",
    "        \"question_count\": analysis[\"total_questions\"],\n",
    "        \"biased_tokens_count\": len(analysis[\"token_bias\"]),\n",
    "        \"top_biased_tokens\": list(analysis[\"token_bias\"].keys())[:5],\n",
    "        \"option_importance_variance\": max([d[\"relative_importance\"] for d in analysis[\"option_importance\"].values()]) \n",
    "                                     if analysis[\"option_importance\"] else None\n",
    "    }\n",
    "\n",
    "# Save summary\n",
    "with open(\"shap_analysis_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f)\n",
    "\n",
    "# Create a CSV with the most important findings\n",
    "summary_df = pd.DataFrame()\n",
    "for demo in demographic_cols:\n",
    "    if demo in demographic_analysis:\n",
    "        summary_df.loc[demo, \"Question Count\"] = demographic_analysis[demo][\"total_questions\"]\n",
    "        summary_df.loc[demo, \"Avg Confidence\"] = demographic_analysis[demo][\"average_confidence\"]\n",
    "        summary_df.loc[demo, \"Biased Tokens\"] = len(demographic_analysis[demo][\"token_bias\"])\n",
    "        \n",
    "        # Add option importance data\n",
    "        for option in choices_cols:\n",
    "            if option in demographic_analysis[demo][\"option_importance\"]:\n",
    "                rel_imp = demographic_analysis[demo][\"option_importance\"][option][\"relative_importance\"]\n",
    "                summary_df.loc[demo, f\"{option} Rel Importance\"] = rel_imp\n",
    "\n",
    "summary_df.to_csv(\"demographic_bias_summary.csv\")\n",
    "\n",
    "print(\"Enhanced SHAP analysis completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
