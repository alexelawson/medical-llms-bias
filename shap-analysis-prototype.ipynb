{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "\n",
    "# Load the multiple-choice model and tokenizer\n",
    "MODEL_NAME = \"model of choice\"  # Replace with a fine-tuned MCQ model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset.csv\")  # Replace with actual dataset path\n",
    "\n",
    "# Filter dataset to only include single-choice questions\n",
    "df = df[df[\"choice_type\"] == \"Single\"]\n",
    "\n",
    "# Extract relevant columns\n",
    "question_col = \"Augmented_Question\"  # Use the question with demographic variable\n",
    "choices_cols = [\"opa\", \"opb\", \"opc\", \"opd\"]\n",
    "correct_col = \"cop\"\n",
    "demographic_cols = [\"Male\", \"Female\", \"White\", \"Black\", \"Arab\", \"Asian\", \"Other\", \"Low\", \"Middle\", \"High\"]\n",
    "\n",
    "# Format input for multiple-choice models\n",
    "def format_mcq(row):\n",
    "    choices = [row[col] for col in choices_cols]\n",
    "    encodings = tokenizer([row[question_col]] * len(choices), choices, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return encodings\n",
    "\n",
    "# Define prediction function\n",
    "def f_mcq(x):\n",
    "    \"\"\"SHAP function to get logits for multiple-choice questions.\"\"\"\n",
    "    batch = tokenizer([x[\"question\"]] * len(x[\"choices\"]), x[\"choices\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    # Add batch dimension\n",
    "    for key in batch:\n",
    "        batch[key] = batch[key].unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    return outputs.logits.numpy()\n",
    "\n",
    "# Define token-to-string mapping\n",
    "def out_names(x):\n",
    "    return tokenizer.convert_ids_to_tokens(x)\n",
    "\n",
    "f_mcq.output_names = out_names\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "masker = shap.maskers.Text(tokenizer)\n",
    "explainer = shap.Explainer(f_mcq, masker)\n",
    "\n",
    "# Process the entire dataset and group by demographic variables\n",
    "shap_results = []\n",
    "for index, row in df.iterrows():\n",
    "    sample_input = {\"question\": row[question_col], \"choices\": [row[col] for col in choices_cols]}\n",
    "    shap_values = explainer([sample_input])\n",
    "    \n",
    "    # Store SHAP results along with demographic information\n",
    "    result = {\"index\": index, \"shap_values\": shap_values, \"demographics\": {col: row[col] for col in demographic_cols}}\n",
    "    shap_results.append(result)\n",
    "\n",
    "# Convert results to a DataFrame for further analysis\n",
    "shap_df = pd.DataFrame(shap_results)\n",
    "shap_df.to_csv(\"shap_results.csv\", index=False)  # Save results for later analysis\n",
    "\n",
    "# Visualize an example explanation\n",
    "# shap.plots.text(shap_results[0][\"shap_values\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
